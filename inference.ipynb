{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from DatasetParse import data_spilt, ReadH5Pkld, get_loader\n",
    "from TrainInference import inference_net, inference_net_lesion, count_unique_contours\n",
    "from monai.transforms import *\n",
    "\n",
    "from monai.losses import DiceLoss, FocalLoss, DiceFocalLoss\n",
    "from monai.networks.nets.swin_unetr import SwinUNETR\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "use_dwi = False\n",
    "model_path = 'archive_models_325/t2_adc_swin.ptm'\n",
    "device='cpu'\n",
    "base_dir = '/raid/candi/xiangcen/data_all_modality__update_crop'\n",
    "\n",
    "if use_dwi:\n",
    "    base_dir = '/raid/candi/xiangcen/data_all_modality_update_crop_three'\n",
    "train_list, inference_list = data_spilt(base_dir, 745, seed=325)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "inference_transform = ReadH5Pkld()\n",
    "\n",
    "\n",
    "\n",
    "inference_loader = get_loader(inference_list, inference_transform, batch_size=1)\n",
    "in_chan = 3\n",
    "if use_dwi:\n",
    "    in_chan = 4\n",
    "model = SwinUNETR(img_size=(128, 128, 64), in_channels=in_chan, out_channels=3, downsample='mergingv2', use_v2=True)\n",
    "model.load_state_dict(torch.load(model_path, map_location=device, weights_only=True))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def post_process(x: torch.tensor):\n",
    "    \n",
    "    x = torch.argmax(x, dim=1)\n",
    "    return x.to(float)\n",
    "\n",
    "def inference_post_process(o):\n",
    "    o = post_process(o) # make sure all value ins between 0-1\n",
    "    return o # just get the \n",
    "\n",
    "\n",
    "# remember the loader should drop the last batch to prevent differenct sequence number in the last batch\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "TP_gt, FP_gt = 0, 0\n",
    "TP_pred, FP_pred = 0, 0\n",
    "\n",
    "for batch in inference_loader:\n",
    "    # print(batch[\"patient_name\"], batch[\"patient_uid\"])\n",
    "    img, label = batch[\"img\"].to(device), batch[\"label\"].to(device)\n",
    "    tumor = (label != 0).float()\n",
    "    img = torch.cat([\n",
    "        img,\n",
    "        tumor\n",
    "    ], dim=1)\n",
    "    \n",
    "    _, num_unique = count_unique_contours(label)\n",
    "    print(num_unique)\n",
    "    \n",
    "    \n",
    "    # forward pass\n",
    "    output = model(img)\n",
    "    output = inference_post_process(output)\n",
    "    \n",
    "    \n",
    "    priads_sheet = pd.read_excel('Target-Data_2019-12-05-2.xlsx')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    patient_name, patient_uid = batch['patient_name'][0], batch['patient_uid']\n",
    "    for uid in patient_uid:\n",
    "        filtered_df = priads_sheet[priads_sheet['Patient ID'] == patient_name]\n",
    "        filtered_df = filtered_df[filtered_df['seriesInstanceUID_MR'] == uid]\n",
    "        filtered_df = filtered_df.drop_duplicates(subset='ROI Volume (cc)')\n",
    "        print(patient_name, uid)\n",
    "        print(filtered_df['UCLA Score (Similar to PIRADS v2)'])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break\n",
    "output = output.cpu().detach().numpy()\n",
    "label = label.cpu().detach().numpy()\n",
    "img = img.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 8, 8\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "axes = axes.flatten()  # Flatten to easily index axes\n",
    "\n",
    "for i in range(rows * cols):\n",
    "\n",
    "    # axes[i].imshow(img[0, 1, :, :, i], cmap='gray')  # Adjust cmap if needed\n",
    "    axes[i].imshow(output[0, :, :, i] == 1, cmap='gray')  # Adjust cmap if needed\n",
    "    axes[i].contour(label[0, 0, :, :, i] == 1, levels=[0.5], colors='red')\n",
    "    axes[i].contour(label[0, 0, :, :, i] == 2, levels=[0.5], colors='green')\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 8, 8\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "axes = axes.flatten()  # Flatten to easily index axes\n",
    "\n",
    "for i in range(rows * cols):\n",
    "\n",
    "    axes[i].imshow(img[0, 0, :, :, i], cmap='gray')  # Adjust cmap if needed\n",
    "    axes[i].contour(output[0, :, :, i] == 1, linewidths=4, colors='orange')  # Adjust cmap if needed\n",
    "    axes[i].contour(label[0, 0, :, :, i] == 1, levels=[0.5], colors='red')\n",
    "    axes[i].contour(label[0, 0, :, :, i] == 2, levels=[0.5], colors='green')\n",
    "    axes[i].axis('off')  # Hide axes\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label = label.cpu()\n",
    "# print(torch.unique(label))\n",
    "# rows, cols = 8, 8\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "# axes = axes.flatten()  # Flatten to easily index axes\n",
    "# for i in range(rows * cols):\n",
    "\n",
    "#     axes[i].imshow(label[0, 0, :, :, i], cmap='gray')  # Adjust cmap if needed\n",
    "#     axes[i].axis('off')  # Hide axes\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = img.cpu()\n",
    "# # print(torch.unique(label))\n",
    "# rows, cols = 8, 8\n",
    "# fig, axes = plt.subplots(rows, cols, figsize=(12, 12))\n",
    "# axes = axes.flatten()  # Flatten to easily index axes\n",
    "# for i in range(rows * cols):\n",
    "\n",
    "#     axes[i].imshow(img[0, 1, :, :, i], cmap='gray')  # Adjust cmap if needed\n",
    "#     axes[i].axis('off')  # Hide axes\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
